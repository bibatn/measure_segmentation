{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import catalyst\n",
    "from catalyst import utils\n",
    "#from catalyst.utils import metrics\n",
    "from catalyst.contrib.nn import RAdam, Lookahead\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# import albumentations as albu\n",
    "# from albumentations.pytorch.transforms import ToTensor\n",
    "\n",
    "from nami_segmentation.datasets import DatasetNami\n",
    "from nami_segmentation.utils import create_tensorboard_writers, show_imgmask, visualize\n",
    "from nami_segmentation.models.bisenetv2_aux_dw import BiSeNetV2_aux_dw\n",
    "from nami_segmentation.loss_functions import combo_seg_loss, compute_tp_fp_fn\n",
    "from nami_segmentation.training import fit\n",
    "import nami_segmentation.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "HEIGHT = 512\n",
    "WIDTH = 1024\n",
    "\n",
    "NUM_WORKERS = 16\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "CLASSES = ['person', \n",
    "           'vehicle',\n",
    "           'bicycle', \n",
    "           'lstart/env/bin/python3 ight', \n",
    "           'sign', \n",
    "           'road', \n",
    "           'moto', \n",
    "           'zebra', \n",
    "           'dashed', \n",
    "           'solid',\n",
    "           'doublesolid']\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "nami_seg_folder = '/mnt/data/VideoAi/Khabibulin/DB_segmentation_copy_121121'\n",
    "\n",
    "train_folders = [\n",
    "# 'cf_short_221130_train',\n",
    "# 'cf_221130_train',\n",
    "'!!180115_12_kol_CVAT',\n",
    "'!!180202_11_anu_CVAT',\n",
    "'!!180222_12_ant_CVAT(НАМИ)',\n",
    "'!!180226_11_shy_CVAT',\n",
    "'!!180226_12_shu_CVAT',\n",
    "'!!180226_14_ush_CVAT',\n",
    "'!!180115_13_ant_CVAT',\n",
    "'!!180329_15_ant_CVAT',\n",
    "'!!180405_12_ant_CVAT',\n",
    "'!!180510_14_anu_CVAT',\n",
    "'!!180723_11_2_ush_CVAT',\n",
    "'!!190116_15_ush_CVAT',\n",
    "'!!190318_11_kol_CVAT',\n",
    "'!!190325_15_ant_CVAT',\n",
    "'!!190401_11_kol_CVAT',\n",
    "'!!190401_12_anu_CVAT',\n",
    "'!!190415_12_ush_CVAT',\n",
    "'!!190516_11_ush_CVAT',\n",
    "#'!!190516_12_ush_CVAT',\n",
    "'!!190516_13_ush',\n",
    "'!!190606_10_3_anu_CVAT',\n",
    "'!!190613_09_shu_CVAT',\n",
    "'!!190718_17_ant_CVAT',\n",
    "'!!190912_15_ant_CVAT',\n",
    "'!!190527_14_CVAT',\n",
    "'!!201014_11_kol_CVAT(НАМИ)'\n",
    "]\n",
    "\n",
    "valid_folders = [\n",
    "# 'cf_short_221130_valid',\n",
    "# 'cf_221130_valid',\n",
    "'!!180216_12_ant_CVAT',\n",
    "'!!180226_13_kol_CVAT',\n",
    "'!!180226_15_ush_CVAT',\n",
    "'!!180329_14_ant_CVAT',\n",
    "'!!180405_11_ant_CVAT',\n",
    "'!!190408_14_kol_CVAT',\n",
    "'!!180510_11_ush_CVAT',\n",
    "'!!180618_10_anu_CVAT',\n",
    "'!!180723_13_ush_CVAT',\n",
    "'!!190712_08_ush_CVAT'\n",
    "]\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0003\n",
    "NUM_EPOCHS = 1500\n",
    "\n",
    "LOG_DIR = \"logs\"\n",
    "\n",
    "model = BiSeNetV2_aux_dw(len(CLASSES))\n",
    "weights_path = '/mnt/work/krapukhin/projects/segmentation_new/training/bisenetv2_namicsaudi_512x1024_pe-ve-bi-li-si-ro-mo-ze-da-so-do_combo_191121/trained_models/best_585.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "print(f\"device: {device}\")\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# current_model_dict = model.state_dict()\n",
    "loaded_state_dict = torch.load(weights_path)\n",
    "# new_state_dict={k:v if v.size()==current_model_dict[k].size()  else  current_model_dict[k] for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "# new_state_dict['module.head.conv_out.weight'][:-3, :, :, :] = loaded_state_dict['module.head.conv_out.weight']\n",
    "# new_state_dict['module.head.conv_out.bias'][:-3] = loaded_state_dict['module.head.conv_out.bias']\n",
    "# new_state_dict['module.aux2.conv_out.weight'][:-3, :, :, :] = loaded_state_dict['module.aux2.conv_out.weight']\n",
    "# new_state_dict['module.aux2.conv_out.bias'][:-3] = loaded_state_dict['module.aux2.conv_out.bias']\n",
    "# new_state_dict['module.aux3.conv_out.weight'][:-3, :, :, :] = loaded_state_dict['module.aux3.conv_out.weight']\n",
    "# new_state_dict['module.aux3.conv_out.bias'][:-3] = loaded_state_dict['module.aux3.conv_out.bias']\n",
    "# new_state_dict['module.aux4.conv_out.weight'][:-3, :, :, :] = loaded_state_dict['module.aux4.conv_out.weight']\n",
    "# new_state_dict['module.aux4.conv_out.bias'][:-3] = loaded_state_dict['module.aux4.conv_out.bias']\n",
    "# new_state_dict['module.aux5_4.conv_out.weight'][:-3, :, :, :] = loaded_state_dict['module.aux5_4.conv_out.weight']\n",
    "# new_state_dict['module.aux5_4.conv_out.bias'][:-3] = loaded_state_dict['module.aux5_4.conv_out.bias']\n",
    "# model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.13.1+cu117, catalyst: 21.07\n"
     ]
    }
   ],
   "source": [
    "train_writer, val_writer = create_tensorboard_writers()\n",
    "\n",
    "utils.set_global_seed(SEED)\n",
    "utils.prepare_cudnn(deterministic=True)\n",
    "\n",
    "print(f\"torch: {torch.__version__}, catalyst: {catalyst.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentations\n",
    "train_transforms = transforms.compose([\n",
    "    transforms.random_crop_nami(),\n",
    "    transforms.resize_transforms(HEIGHT, WIDTH), \n",
    "    transforms.hard_transforms(), \n",
    "    transforms.post_transforms(),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.compose([\n",
    "    transforms.center_crop_nami(), \n",
    "    transforms.pre_transforms(HEIGHT, WIDTH), \n",
    "    transforms.post_transforms()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.compose([\n",
    "    transforms.pre_transforms(HEIGHT, WIDTH), \n",
    "    transforms.resize_transforms(HEIGHT, WIDTH), \n",
    "    transforms.post_transforms()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/krapukhin/projects/segmentation/datasets/DB_segmentation_copy_121121/!!190912_15_ant_CVAT/190912_152005_000085.png\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lstart/env/bin/python3 ight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DatasetNami(nami_seg_folder, train_folders, classes\u001b[38;5;241m=\u001b[39mCLASSES, augmentation\u001b[38;5;241m=\u001b[39mtrain_transforms, full_road\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshow_imgmask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/start/nami_segmentation/utils.py:33\u001b[0m, in \u001b[0;36mshow_imgmask\u001b[0;34m(idx, dataset, mask_id)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_imgmask\u001b[39m(idx, dataset, mask_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Show image, mask and mask on image\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     img_mask \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m     image \u001b[38;5;241m=\u001b[39m img_mask[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     35\u001b[0m     image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mmin(image))\n",
      "File \u001b[0;32m~/start/nami_segmentation/datasets.py:350\u001b[0m, in \u001b[0;36mDatasetNami.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnami_selected_classes:\n\u001b[1;32m    349\u001b[0m     class_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(mask\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 350\u001b[0m     required_colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_paths_to_colormap\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m required_colors:\n\u001b[1;32m    352\u001b[0m         class_mask \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (mask[:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m k[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m (mask[:, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m k[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m&\u001b[39m (mask[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m k[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lstart/env/bin/python3 ight'"
     ]
    }
   ],
   "source": [
    "dataset = DatasetNami(nami_seg_folder, train_folders, classes=CLASSES, augmentation=train_transforms, full_road=True)\n",
    "show_imgmask(random.randint(0, len(dataset) - 1), dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6206\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetNami(nami_seg_folder, train_folders, classes=CLASSES, augmentation=train_transforms, full_road=True)\n",
    "valid_dataset = DatasetNami(nami_seg_folder, valid_folders, classes=CLASSES, augmentation=valid_transforms, full_road=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, drop_last=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_optimizer = RAdam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = Lookahead(base_optimizer)\n",
    "scheduler = None\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6671ad11c80317f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6671ad11c80317f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR} --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/khabibulin/start/nami_segmentation/datasets.py\", line 349, in __getitem__\n    required_colors = self.mask_paths_to_colormap[self.mask_paths[i]][cls]\nKeyError: 'lstart/env/bin/python3 ight'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCLASSES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombo_seg_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/start/nami_segmentation/training.py:23\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(num_epochs, num_classes, model, device, train_loader, valid_loader, criterion, optimizer, scheduler, train_writer, val_writer, seed)\u001b[0m\n\u001b[1;32m     21\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain batch \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_loader)), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m     imgs, masks \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/start/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/start/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/start/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/start/env/lib/python3.8/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/khabibulin/start/env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/khabibulin/start/nami_segmentation/datasets.py\", line 349, in __getitem__\n    required_colors = self.mask_paths_to_colormap[self.mask_paths[i]][cls]\nKeyError: 'lstart/env/bin/python3 ight'\n"
     ]
    }
   ],
   "source": [
    "fit(NUM_EPOCHS, len(CLASSES), model, device, train_loader, valid_loader, combo_seg_loss, optimizer, scheduler, train_writer, val_writer, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.flush()\n",
    "train_writer.close()\n",
    "val_writer.flush()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model from epoch 585 saved\n",
    "#585/1500 l:1.00e-03 t:3.957 v:0.600 [0.55 0.84 0.00 0.56 0.76 0.90 0.00 0.57 0.49 0.49 0.70] 0.87 0.53 4598"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
